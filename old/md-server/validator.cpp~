#include "validator.h"

pthread_t validate_thread;
bool running = true;

// ping a gateway to verify that this entry still exists
bool validate( char* path, void* arg ) {

   // skip directories
   if( MD_ENTRY_PATH_ISDIR( path ) )
      return true;

   
   // get the metadata entry 
   struct md_entry ent;
   memset( &ent, 0, sizeof(ent) );

   int status = 0;
   
   int rc = md_read_entry( "/", path, &ent );
   if( rc != 0 ) {
      errorf( "could not read %s\n", path );
      return false;
   }

   // read it
   CURL* curl_h = (CURL*)arg;

   curl_easy_setopt( curl_h, CURLOPT_URL, ent.url );
   rc = curl_easy_perform( curl_h );
   if( rc != 0 ) {
      // error
      errorf( "could not stat %s, rc = %d\n", ent.url, rc );
      status = -ENOENT;
   }

   if( status != 0 ) {
      // remove from the metadata
      md_remove_mc_entry( (char*)"/", &ent );
   }

   md_entry_free( &ent );

   // don't process this entry; we're done
   return false;
}

void* validator_run( void* arg ) {
   // continuously walk the master copy and verify that each gateway still has the files it claims it has
   struct md_syndicate_conf* conf = (struct md_syndicate_conf*)arg;
   
   while( running ) {
      CURL* curl_h = curl_easy_init();

      curl_easy_setopt( curl_h, CURLOPT_NOPROGRESS, 1L );   // no progress bar
      curl_easy_setopt( curl_h, CURLOPT_NOSIGNAL, 1L );
      curl_easy_setopt( curl_h, CURLOPT_USERAGENT, "Syndicate-agent/1.0");
      curl_easy_setopt( curl_h, CURLOPT_FOLLOWLOCATION, 1L );
      curl_easy_setopt( curl_h, CURLOPT_FILETIME, 1L );
      curl_easy_setopt( curl_h, CURLOPT_CONNECTTIMEOUT, conf->metadata_connect_timeout );
      curl_easy_setopt( curl_h, CURLOPT_TIMEOUT, conf->transfer_timeout );
      curl_easy_setopt( curl_h, CURLOPT_NOBODY, 1L );

      // walk the master copy
      struct md_entry** dumb = md_walk_fs_dir( conf->master_copy_root, true, false, validate, curl_h, NULL, NULL );
      md_entry_free_all( dumb );
      free( dumb );

      curl_easy_cleanup( curl_h );

      sleep(60);
   }

   return NULL;
}

int validator_init( struct md_syndicate_conf* conf ) {
   dbprintf("%s", "Starting validator thread\n");
   validate_thread = md_start_thread( validator_run, conf, false );
   return 0;
}

int validator_shutdown() {
   dbprintf("%s", "Stopping validator thread\n");
   running = false;
   pthread_cancel( validate_thread );
   pthread_join( validate_thread, NULL );
   return 0;
}

/*
// generate a metadata entry from a curl handle
static int md_header_from_curl_h( struct md_entry* hdr, CURL* curl_h ) {
   long last_mod = -1;
   long response_code = -1;
   double size = -1;
   char* effective_url = NULL;
   int rc = 0;

   curl_easy_getinfo( curl_h, CURLINFO_RESPONSE_CODE, &response_code );

   if( response_code < 400 ) {
      if( curl_easy_getinfo( curl_h, CURLINFO_CONTENT_LENGTH_DOWNLOAD, &size ) != CURLE_OK )
         rc = -ENODATA;

      if( curl_easy_getinfo( curl_h, CURLINFO_EFFECTIVE_URL, &effective_url ) != CURLE_OK )
         rc = -ENODATA;

      if( curl_easy_getinfo( curl_h, CURLINFO_FILETIME, &last_mod ) != CURLE_OK )
         rc = -ENODATA;

      if( rc == 0 ) {
         memset( hdr, 0, sizeof(struct md_entry) );
         hdr->url = effective_url;
         hdr->size = (off_t)size;
         hdr->mtime_sec = (time_t)last_mod;
         hdr->mtime_nsec = 0;
      }
      else {
         if( effective_url )
            free( effective_url );
      }
   }
   else {
      rc = -response_code;
   }

   return rc;
}


// create a validate handle
ValidateHandle::ValidateHandle( struct md_entry* ent, time_t query_timeout ) {
   this->ent = ent;
   this->state = VALIDATE_INIT;
   
   this->num_urls = 0;
   SIZE_LIST( &this->num_urls, ent->url_replicas );
   this->num_urls++;    // for the original URL
   
   this->curl_hs = CALLOC_LIST( CURL*, this->num_urls + 1 );
   
   this->url_status = CALLOC_LIST( int, this->num_urls + 1 );
   
   this->curl_hs[0] = curl_easy_init();
   md_init_curl_handle( this->curl_hs[0], ent->url, query_timeout );
   curl_easy_setopt( this->curl_hs[0], CURLOPT_NOBODY, 1L );
   
   this->url_status[0] = VALIDATE_UNKNOWN;
   
   for( int i = 1; i <= this->num_urls; i++ ) {
      this->curl_hs[i] = curl_easy_init();
      md_init_curl_handle( this->curl_hs[i], ent->url_replicas[i-1], query_timeout );
      curl_easy_setopt( this->curl_hs[i], CURLOPT_NOBODY, 1L );
      this->url_status[i] = VALIDATE_UNKNOWN;
   }
   
   // the root directory is automatically good, since we always own it
   if( strcmp( ent->path, "/" ) == 0 ) {
      this->url_status[0] = VALIDATE_GOOD;
   }
   
   this->queried = md_entry_dup( this->ent );
}


// destroy a validate handle
ValidateHandle::~ValidateHandle() {
   if( this->curl_hs ) {
      for( int i = 0; i < this->num_urls + 1; i++ ) {
         curl_easy_cleanup( this->curl_hs[i] );
      }
      free( this->curl_hs );
      this->curl_hs = NULL;
   }

   if( this->ent ) {
      md_entry_free( this->ent );
      free( this->ent );
      this->ent = NULL;
   }
   
   if( this->queried ) {
      md_entry_free( this->queried );
      free( this->queried );
      this->queried = NULL;
   }
   
   if( this->url_status ) {
      free( this->url_status );
      this->url_status = NULL;
   }
}


// set up the validator threadpool
ValidatorThreadpool::ValidatorThreadpool( struct md_syndicate_conf* conf, Blacklist* bl, chk_producer pf, void* cls )
 : Threadpool<ValidateHandle>( MAX( conf->num_crawlers, 1 ), VALIDATOR_THREAD_WORKSIZE, false ),
   CURLTransfer( MAX( conf->num_crawlers, 1 ) ) {
   
   this->conf = conf;
   this->bl = bl;
   
   this->pending = new vector<ValidateHandle*>[ this->num_threads ];
   this->done = true;
   this->mc_has_more = pf;
   this->cls = cls;
}


// destroy the validator threadpool
ValidatorThreadpool::~ValidatorThreadpool() {
   for( int i = 0; i < this->num_threads; i++ ) {
      ValidateHandle* vh = this->get_work( i );
      if( vh ) {
         do {
            for( int j = 0; j < vh->num_urls; j++ ) {
               this->remove_curl_easy_handle( i, vh->curl_hs[j] );
            }
            
            for( unsigned int j = 0; j < this->pending[i].size(); j++ ) {
               if( this->pending[i][j] == vh ) {
                  this->pending[i][j] = NULL;
               }
            }
            delete vh;
            vh = this->get_work( i );
         } while( vh != NULL );
      }
   }
   
   for( int i = 0; i < this->num_threads; i++ ) {
      for( unsigned int j = 0; j < this->pending[i].size(); j++ ) {
         if( this->pending[i][j] ) {
            delete this->pending[i][j];
            this->pending[i][j] = NULL;
         }
      }
   }
   
   delete[] this->pending;
   fflush( stdout );
}


// re-set the "done" status--we're gonna get some work
void ValidatorThreadpool::begin() {
   this->done = false;
}

// wait until nothing left to validate
void ValidatorThreadpool::wait( int delay ) {
   while( !this->done ) {
      usleep( delay );
   }
}


// update a metadata entry's info from information obtained by querying its primary URL
// return > 0 ==>  we added information 
// return == 0 ==> no problems, but we changed nothing
// return < 0 ==> invalid
int ValidateHandle::update_primary( md_header* primary_info, struct md_syndicate_conf* conf ) {
   int rc = 0;

   if( strcmp(this->ent->url, primary_info->url) != 0 ) {
      // primary effective URL changed
      if( this->queried->url )
         free( this->queried->url );
      this->queried->url = strdup( primary_info->url );
      
      rc = 1;
   }
   if( this->queried->mtime_sec + conf->clock_skew < primary_info->mtime_sec || this->queried->mtime_sec - conf->clock_skew > primary_info->mtime_sec) {
      // URLs have not changed, but timestamps have.  Got modified--not good
      printf("local mtime = %lld, remote mtime = %lld\n", this->queried->mtime_sec, primary_info->mtime_sec);
      errorf("ValidateHandle::update_primary: invalid mtime on %s\n", this->queried->path );
      rc = -EINVAL;
   }
   else {
      this->queried->mtime_sec = primary_info->mtime_sec;
      rc = 1;
   }
   
   return rc;
}


// update a metadata entry's info from information obtained by querying one of its replicas
// return > 0 ==> we added information
// return == 0 ==> no problems, but we changed nothing
// return < 0 ==> invalid
int ValidateHandle::update_replica( md_header* replica_info, struct md_syndicate_conf* conf ) {
   int rc = 0;
   
   // ensure the metadata is consistent with the primary.
   if( replica_info->size != this->queried->size ) {
      errorf("ValidateHandle::update_replica: invalid size %lld on %s (at %s)\n", replica_info->size, replica_info->path, replica_info->url );
      return -EINVAL;
   }
   
   if( this->queried->mtime_sec + conf->clock_skew < replica_info->mtime_sec || this->queried->mtime_sec - conf->clock_skew > replica_info->mtime_sec ) {
      // replica is too old or too new
      printf("queried mtime = %lld, replica mtime = %lld\n", this->queried->mtime_sec, replica_info->mtime_sec );
      errorf("ValidateHandle::update_replica: invalid mtime %lld on %s (at %s)\n", replica_info->mtime_sec, replica_info->path, replica_info->url );
      return -EINVAL;
   }
   
   return rc;
}


// process a valid metadata entry by committing it to the master copy
// return 0 on success, negative on failure
int ValidateHandle::commit_valid_query( struct md_syndicate_conf* conf ) {
   return md_add_mc_entry( conf->master_copy_root, this->queried );
}


// remove an invalid entry from the master copy
int ValidateHandle::commit_invalid_query( struct md_syndicate_conf* conf ) {
   int rc = 0;
   if( conf->bad_mtime_policy == BAD_MTIME_POLICY_REMOVE ) {
      // remove this entry.
      // If somehow a directory became invalid, but it still has valid children,
      // this method will fail accordingly
      rc = md_remove_mc_entry( conf->master_copy_root, this->queried );
   }
   return rc;
}


// process an entry
int ValidateHandle::commit_queried( struct md_syndicate_conf* conf ) {
   int rc = 0;
   
   // consolidate list of replicas into only the good replicas
   int num_replicas = this->num_urls - 1;
   for( int i = 1; i <= this->num_urls - 1; i++ ) {
      if( this->url_status[i] == VALIDATE_BAD ) {
         free( this->queried->url_replicas[i-1] );
         this->queried->url_replicas[i-1] = NULL;
         num_replicas --;
      }
   }
   
   char** good_replicas = CALLOC_LIST( char*, num_replicas + 1 );
   int cnt = 0;
   
   for( int i = 1; i <= this->num_urls - 1; i++ ) {
      if( this->url_status[i] == VALIDATE_GOOD ) {
         good_replicas[cnt] = this->queried->url_replicas[i-1];
         cnt++;
      }
   }
   
   free( this->queried->url_replicas );
   this->queried->url_replicas = good_replicas;
   
   if( cnt + (this->url_status[0] == VALIDATE_GOOD ? 1 : 0) > 0 ) {
      // at least one URL is valid
      rc = this->commit_valid_query( conf );
   }
   else {
      rc = this->commit_invalid_query( conf );
   }
   
   if( rc != 0 ) {
      errorf("ValidateHandle::commit_queried: could not process entry %s\n", this->queried->path );
   }
   else {
      dbprintf("ValidateHandle::commit_queried: processed %s\n", this->queried->path );
   }
   return rc;
}


// add work to a random thread in this threadpool
int ValidatorThreadpool::add_work( ValidateHandle* work ) {
   return this->add_work( work, rand() % this->num_threads );
}

// add work to this threadpool by first registering its CURL handle with our multihandle and pending list
int ValidatorThreadpool::add_work( ValidateHandle* work, int thread_no ) {
   for( int i = 0; i < work->num_urls; i++ ) {

      int rc = this->add_curl_easy_handle( thread_no, work->curl_hs[i] );
      if( rc != 0 ) {
         errorf("ValidatorThreadpool(%d)::add_work: add_curl_easy_handle rc = %d\n", thread_no, rc );
         return rc;
      }
      else {
         // add this to pending
         unsigned int i = 0;
         for( i = 0; i < this->pending[thread_no].size(); i++ ) {
            if( this->pending[thread_no][i] == NULL ) {
               this->pending[thread_no][i] = work;
               break;
            }
         }
         if( i == this->pending[thread_no].size() ) {
            this->pending[thread_no].push_back( work );
         }
      }
   }
   int rc = Threadpool<ValidateHandle>::add_work( work, thread_no );
   return rc;
}


// remove work from this threadpool by removing its CURL handle form our multihandle and pending list
int ValidatorThreadpool::remove_work( ValidateHandle* work, int thread_no ) {

   for( int i = 0; i < work->num_urls; i++ ) {
      this->remove_curl_easy_handle( thread_no, work->curl_hs[i] );
   }
   
   for( unsigned int i = 0; i < this->pending[thread_no].size(); i++ ) {
      if( this->pending[thread_no][i] == work ) {
         this->pending[thread_no][i] = NULL;
      }
   }
   
   return 0;
}


// update the state of a validator handle
int ValidateHandle::update_state( ValidatorThreadpool* vp ) {
  
   int rc = 0;
   
   // update the state of this work
   switch( this->state ) {
      
      case VALIDATE_INIT: {
         this->state = VALIDATE_RUN;
         
         break;
      }
      
      case VALIDATE_DONE: {
         
         rc = -1;
         dbprintf("ValidateHandle::update_state: finished %s (%p)\n", this->ent->path, this );
         
         break;
      }
      
      case VALIDATE_RUN: {
         // is this handle done?
         bool vh_done = true;
         for( int i = 0; i < this->num_urls; i++ ) {
            if( this->url_status[i] == VALIDATE_UNKNOWN ) {
               vh_done = false;
               break;
            }
         }
         
         
         if( vh_done ) {
            this->state = VALIDATE_DONE;
            
            // add/remove from master copy, if needed
            this->commit_queried( vp->get_conf() );
         }
         
         rc = this->state;
         break;
      }
      default:
         break;
   }
   
   return rc;
}


// get the validator handle who had a URL that finished downloading
ValidateHandle* ValidatorThreadpool::next_ready_handle( int thread_no, int* which_url, int* err ) {
   
   CURLMsg* msg = NULL;
   *which_url = -1;
   *err = 0;
   ValidateHandle* vh = NULL;
   
   do {
      msg = this->get_next_curl_msg( thread_no );
      if( msg ) {
         if( msg->msg == CURLMSG_DONE ) {
            
            for( unsigned int i = 0; i < this->pending[thread_no].size(); i++ ) {
               if( this->pending[thread_no][i] != NULL ) {
                  
                  ValidateHandle* tmp = this->pending[thread_no][i];
                  
                  if( tmp ) {
                     for( int j = 0; j < tmp->num_urls; j++ ) {
                        if( tmp->curl_hs[j] == msg->easy_handle ) {
                           *which_url = j;
                           vh = tmp;
                           break;
                        }
                     }
                     
                     if( vh )
                        break;
                  }
               }
            }
         }
      }
   } while( msg != NULL && vh == NULL );
   
   if( vh != NULL ) {
      // ensure that the download finished successfully
      if( msg->data.result != 0 ) {
         *err = msg->data.result;
      }
   }
   return vh;
}



// process an entry
int ValidatorThreadpool::process_work( ValidateHandle* work, int thread_no ) {
   if( this->done ) {
      usleep( 5000 );
      return 0;
   }
   int rc = 0;
   
   if( work ) {
      // add new work
      rc = work->update_state( this );
      if( rc < 0 ) {
         // done with work
         this->remove_work( work, thread_no );
         delete work;
         work = NULL;
      }
      else {
         // re-enqueue this work for later
         this->insert_work( work, thread_no );
      }
   }
   
   rc = this->process_curl( thread_no );
   
   int which = 0;
   ValidateHandle* vh = NULL;
   
   do {
      vh = this->next_ready_handle( thread_no, &which, &rc );
      
      if( rc == 0 && vh != NULL ) {
         // download completed successfully.
         // Get the existing metadata entry, if possible
         md_header hdr;
         
         // validate this master copy entry
         rc = md_header_from_curl_h( &hdr, vh->curl_hs[which] );
         
         if( rc == 0 ) {
            if( which == 0 ) {
               // we just queried the primary URL
               rc = vh->update_primary( &hdr, this->conf );
            }
            else {
               // we just validated a replica URL
               rc = vh->update_replica( &hdr, this->conf );
            }
            if( rc >= 0 ) {
               // query had valid data
               vh->url_status[which] = VALIDATE_GOOD;
            }
            else {
               // query had invalid data
               vh->url_status[which] = VALIDATE_BAD;
            }
         }
         else {
            // couldn't get info on the remote entry
            if( which == 0 )
               errorf("ERR: metadata for %s (at primary %s) rc = %d\n", vh->ent->path, vh->ent->url, rc );
            else
               errorf("ERR: metadata for %s (at replica %s) rc = %d\n", vh->ent->path, vh->ent->url_replicas[which-1], rc );
            
            vh->url_status[which] = VALIDATE_BAD;
         }
      }
      else {
         if( vh != NULL ) {
            // download was unsuccessful
            if( which == 0 )
               errorf("ERR: query %s (at primary %s) rc = %d\n", vh->ent->path, vh->ent->url, rc );
            else
               errorf("ERR: query %s (at replica %s) rc = %d\n", vh->ent->path, vh->ent->url_replicas[which-1], rc );
            
            vh->url_status[which] = VALIDATE_BAD;
         }
      }
   } while( vh != NULL );
   
   // drive the pending state machines
   bool still_working = false;
   for( int i = 0; i < this->num_threads; i++ ) {
      for( unsigned int j = 0; j < this->pending[i].size(); j++ ) {
         if( this->pending[i][j] != NULL ) {
            still_working = true;
            break;
         }
      }
   }
   
   if( !(*this->mc_has_more)(this->cls) && !still_working && this->work_count() == 0 ) {
      this->done = true;
   }
   
   return 0;
}
*/
         